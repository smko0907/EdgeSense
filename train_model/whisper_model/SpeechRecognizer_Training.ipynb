{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcription Json -> csv 전환 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "input_dir = \"json_dir\"  # JSON 파일이 들어 있는 폴더\n",
    "output_csv = \"train.csv\"\n",
    "audio_base_path = \"data/\"  # wav 파일이 존재하는 경로\n",
    "\n",
    "data = []\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if not filename.endswith(\".json\"):\n",
    "        continue\n",
    "\n",
    "    filepath = os.path.join(input_dir, filename)\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        j = json.load(f)\n",
    "\n",
    "    # 오디오 파일 경로\n",
    "    base_audio_name = os.path.basename(j['mediaUrl'])\n",
    "    audio_path_sd = os.path.join(audio_base_path, base_audio_name)\n",
    "\n",
    "    # SN 버전도 존재할 경우 함께 처리\n",
    "    audio_path_sn = audio_path_sd.replace(\"_SD.wav\", \"_SN.wav\")\n",
    "\n",
    "    # 모든 대화 내용을 하나의 문장으로 합치기\n",
    "    full_text = \" \".join([dialog['speakerText'].strip() for dialog in j['dialogs']])\n",
    "\n",
    "    # SD 버전\n",
    "    data.append((audio_path_sd, full_text))\n",
    "\n",
    "    # SN 버전\n",
    "    if os.path.exists(audio_path_sn):  # SN 파일이 실제 존재할 경우\n",
    "        data.append((audio_path_sn, full_text))\n",
    "\n",
    "# CSV로 저장\n",
    "with open(output_csv, 'w', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"path\", \"text\"])\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"총 {len(data)} 개 항목 저장 완료 → {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "model_name = \"openai/whisper-small\"\n",
    "language = \"ko\"\n",
    "task = \"transcribe\"\n",
    "\n",
    "# 경로 설정\n",
    "base_dir = os.path.dirname(__file__)\n",
    "data_csv_path = os.path.join(base_dir, \"metadata/train.csv\")\n",
    "output_dir = os.path.join(base_dir, \"fine-tuned-model\")\n",
    "\n",
    "# 데이터셋 로드\n",
    "dataset = load_dataset(\"csv\", data_files={\"train\": data_csv_path}, delimiter=\",\")\n",
    "dataset = dataset.cast_column(\"path\", Audio(sampling_rate=16000))\n",
    "\n",
    "# 모델 & 전처리기\n",
    "processor = WhisperProcessor.from_pretrained(model_name, language=language, task=task)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"path\"]\n",
    "    batch[\"input_features\"] = processor.feature_extractor(audio[\"array\"], sampling_rate=16000).input_features[0]\n",
    "    batch[\"labels\"] = processor.tokenizer(batch[\"text\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(prepare_dataset, remove_columns=dataset[\"train\"].column_names)\n",
    "\n",
    "# 학습 설정\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    evaluation_strategy=\"no\",\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=5000,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# 모델 저장\n",
    "model.save_pretrained(output_dir)\n",
    "processor.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
